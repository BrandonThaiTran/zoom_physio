{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils.video import VideoStream, FileVideoStream\n",
    "from imutils import face_utils\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import dlib\n",
    "from collections import OrderedDict\n",
    "from pose_estimator import PoseEstimator\n",
    "from stabilizer import Stabilizer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, ifft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face streamer class \n",
    "class face_streamer:\n",
    "    def __init__(self, predictor_path, filename = None):\n",
    "        self.filename = filename\n",
    "        \n",
    "        # Initialize dlib's face detector (HOG-based)\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        \n",
    "        # Create landmark predictor.\n",
    "        self.predictor = dlib.shape_predictor(\"../detect-face-parts/shape_predictor_68_face_landmarks.dat\")\n",
    "        \n",
    "        # Facial landmarks that we use\n",
    "        self.facial_landmarks_idxs = OrderedDict([\n",
    "            (\"nose\", (27, 36)),\n",
    "            (\"face\", (0, 26))\n",
    "        ])\n",
    "        \n",
    "        # Define the pose estimator and stabilizer \n",
    "        self.height, self.width = 300, 400\n",
    "        self.pose_estimator = PoseEstimator(img_size=(self.height, self.width))\n",
    "        # Define scalar stabilizers for pose.\n",
    "        self.pose_stabilizers = [Stabilizer(state_num=2, measure_num=1, cov_process=0.1, cov_measure=0.1) \n",
    "                            for _ in range(6)]\n",
    "        \n",
    "        # RGB and RPY to track\n",
    "        self.red = []\n",
    "        self.green = []\n",
    "        self.blue = []\n",
    "        self.roll = []\n",
    "        self.pitch = []\n",
    "        self.yaw = []\n",
    "        \n",
    "        \n",
    "    def start_stream(self):\n",
    "        if self.filename:\n",
    "            self.vs = FileVideoStream(self.filename).start()\n",
    "        else:\n",
    "            self.vs = VideoStream(src=0).start()\n",
    "        print(\"[INFO] camera sensor warming up...\")\n",
    "        time.sleep(2.0)\n",
    "            \n",
    "    def end_stream(self):\n",
    "        # Do some cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        self.vs.stop()\n",
    "        del self.vs\n",
    "        self.num_frames = len(self.red)\n",
    "        self.frame_vector = range(self.num_frames)\n",
    "        self.apply_pos()\n",
    "        self.apply_fft()\n",
    "        self.apply_rmns()\n",
    "        self.apply_freq_filtering()\n",
    "    \n",
    "    def stream(self, display_face_bb = False, display_landmarks = False, display_overlay = False,\n",
    "              display_pose_unstable = False, display_pose_stable = False, display_pose_axis = False):\n",
    "        self.start_stream()\n",
    "        # Loop and stream\n",
    "        while True:\n",
    "            # Read and resize the frame\n",
    "            frame = self.vs.read()\n",
    "            frame = imutils.resize(frame, width=400)\n",
    "            # Get grayscale image and extract the bounding boxes with the detector \n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            rects = self.detector(gray, 0)\n",
    "            # Loop over the face detections \n",
    "            for rect in rects:\n",
    "                # Get the bounding box \n",
    "                (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "                # TODO -- take only the ROI, not the whole box \n",
    "                # Get RGB values\n",
    "                self.update_rgb(frame[bY:bH+bY, bX:bW+bX,:]) \n",
    "                # Determine the facial landmarks for the face region, then\n",
    "                # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "                # array.\n",
    "                shape = face_utils.shape_to_np(self.predictor(gray, rect))\n",
    "                # Try pose estimation\n",
    "                pose = self.pose_estimator.solve_pose_by_68_points(shape.astype('float'))\n",
    "                # Stabilize the pose\n",
    "                steady_pose = self.stablize_pose(pose)\n",
    "                # Update RPY values \n",
    "                self.update_rpy(steady_pose)\n",
    "                # Display bounding box if true\n",
    "                if display_face_bb:\n",
    "                    frame = self.display_face_bb(frame, (bX, bY, bW, bH))\n",
    "                # Display facial landmarks if true\n",
    "                if display_landmarks:\n",
    "                    frame = self.display_landmarks(frame, shape)\n",
    "                # Display the landmark overlay if true\n",
    "                if display_overlay:\n",
    "                    frame = self.display_overlay(frame, shape)\n",
    "                # Display the initial pose annotation if true\n",
    "                if display_pose_unstable:\n",
    "                    frame = self.display_pose_unstable(frame, pose)\n",
    "                # Display the stablized pose annotation if true\n",
    "                if display_pose_stable:\n",
    "                    frame = self.display_pose_stable(frame, steady_pose)\n",
    "                # Display the pose axis if true\n",
    "                if display_pose_axis:\n",
    "                    frame = self.display_pose_axis(frame, steady_pose) \n",
    "                    \n",
    "            # Show the frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            # If the `q` key was pressed, break from the loop.\n",
    "            if key == ord(\"q\"):\n",
    "                # Do some cleanup \n",
    "                self.end_stream()\n",
    "                break\n",
    "                \n",
    "    # TODO -- only use the mask values, not just the box \n",
    "    def update_rgb(self, mask):\n",
    "        self.red.append(np.average(mask[:,:,0]) / 255)\n",
    "        self.green.append(np.average(mask[:,:,1]) / 255)\n",
    "        self.blue.append(np.average(mask[:,:,2]) / 255)\n",
    "    \n",
    "    # TODO -- roll and pitch may be switched\n",
    "    def update_rpy(self, steady_pose):\n",
    "        self.roll.append(steady_pose[0][0])\n",
    "        self.pitch.append(steady_pose[0][1])\n",
    "        self.yaw.append(steady_pose[0][2])\n",
    "\n",
    "    # TODO -- apply POS to combine rgb signal into rPPG signal\n",
    "    # current just adds the signals \n",
    "    def apply_pos(self):\n",
    "        self.rppg = [r + g + b for r, g, b in zip(self.red,self.green,self.blue)]\n",
    "    \n",
    "    # TODO -- figure out if this is the correct way to take the FFT\n",
    "    def apply_fft(self):\n",
    "#         self.red_fft = np.abs(fft(self.red))\n",
    "#         self.green_fft = np.abs(fft(self.green))\n",
    "#         self.blue_fft = np.abs(fft(self.blue))\n",
    "        self.rppg_fft = np.abs(fft(self.rppg))\n",
    "        self.roll_fft = np.abs(fft(self.roll))\n",
    "        self.pitch_fft = np.abs(fft(self.pitch))\n",
    "        self.yaw_fft = np.abs(fft(self.yaw))\n",
    "        \n",
    "    # TODO -- Fix\n",
    "    # Applies Rhythmic Motion Noise Suppresion\n",
    "    def apply_rmns(self):\n",
    "        self.combined_rpy_fft = self.roll_fft + self.pitch_fft + self.yaw_fft\n",
    "        self.combined_rpy_fft = self.roll_fft + self.pitch_fft\n",
    "        self.rppg_fft_rmns = self.rppg_fft - self.combined_rpy_fft\n",
    "    \n",
    "    # TODO - Fix freq filtering\n",
    "    def apply_freq_filtering(self):\n",
    "        self.rppg_freq_filtered = np.abs(ifft(self.rppg_fft_rmns))\n",
    "                \n",
    "    def stablize_pose(self, pose):\n",
    "        steady_pose = []\n",
    "        pose_np = np.array(pose).flatten()\n",
    "        for value, ps_stb in zip(pose_np, self.pose_stabilizers):\n",
    "            ps_stb.update([value])\n",
    "            steady_pose.append(ps_stb.state[0])\n",
    "        steady_pose = np.reshape(steady_pose, (-1, 3))\n",
    "        return steady_pose \n",
    "    \n",
    "    def display_face_bb(self, frame, bounds):\n",
    "        (bX, bY, bW, bH) = bounds\n",
    "        # Draw the bounding box on the frame\n",
    "        cv2.rectangle(frame, (bX, bY), (bW+bX, bH+bY), (0, 255, 0), 1)\n",
    "        return frame\n",
    "    \n",
    "    def display_landmarks(self, frame, shape):\n",
    "        for (name, (i, j)) in self.facial_landmarks_idxs.items():\n",
    "            # Loop over the subset of facial landmarks, drawing the specific face part\n",
    "            for (x, y) in shape[i:j]:\n",
    "                cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "        return frame\n",
    "    \n",
    "    # Displays the overlay of the landmarks \n",
    "    def display_overlay(self, frame, shape, colors=None, alpha=0.75):\n",
    "        # Create two copies of the input image -- one for the\n",
    "        # overlay and one for the final output image\n",
    "        overlay = frame.copy()\n",
    "        output = frame.copy()\n",
    "\n",
    "        # If the colors list is None, initialize it with a unique\n",
    "        # color for each facial landmark region\n",
    "        if colors is None:\n",
    "            colors = [(19, 199, 109), (79, 76, 240), (230, 159, 23),\n",
    "                (168, 100, 168), (158, 163, 32),\n",
    "                (163, 38, 32), (180, 42, 220), (100, 150, 250)]\n",
    "\n",
    "        # Loop over the facial landmark regions individually\n",
    "        for (i, name) in enumerate(self.facial_landmarks_idxs.keys()):\n",
    "            # Grab the (x, y)-coordinates associated with the\n",
    "            # face landmark\n",
    "            (j, k) = self.facial_landmarks_idxs[name]\n",
    "            pts = shape[j:k]\n",
    "            if name == 'face':\n",
    "                hull = cv2.convexHull(pts)\n",
    "                cv2.drawContours(overlay, [hull], -1, colors[i], -1)\n",
    "\n",
    "        # Apply the transparent overlay\n",
    "        cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)\n",
    "\n",
    "        # Return the output image\n",
    "        return output\n",
    "    \n",
    "    def display_pose_unstable(self, frame, pose):\n",
    "        self.pose_estimator.draw_annotation_box(frame, pose[0], pose[1], color=(255, 128, 128))\n",
    "        return frame\n",
    "        \n",
    "    def display_pose_stable(self, frame, steady_pose):\n",
    "        self.pose_estimator.draw_annotation_box(frame, steady_pose[0], steady_pose[1], color=(128, 255, 128))\n",
    "        return frame\n",
    "        \n",
    "    def display_pose_axis(self, frame, steady_pose):\n",
    "        self.pose_estimator.draw_axes(frame, steady_pose[0], steady_pose[1])\n",
    "        return frame\n",
    "        \n",
    "    def plot_rgb(self):\n",
    "        plt.title('Normalized RGB values as a function of frames')\n",
    "        plt.plot(self.frame_vector, self.red, color='red', label = 'Red')\n",
    "        plt.plot(self.frame_vector, self.green, color='green', label='Green')\n",
    "        plt.plot(self.frame_vector, self.blue, color='blue', label='Blue')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        \n",
    "    def plot_rppg(self):\n",
    "        plt.title('rPPG signal')\n",
    "        plt.plot(self.frame_vector, self.rppg)\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "    \n",
    "    def plot_rpy(self):\n",
    "        plt.title('RPY values as a function of frames')\n",
    "        plt.plot(self.frame_vector, self.roll, color='cyan', label = 'Roll')\n",
    "        plt.plot(self.frame_vector, self.pitch, color='magenta', label='Pitch')\n",
    "        plt.plot(self.frame_vector, self.yaw, color='yellow', label='Yaw')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        \n",
    "    def plot_fft(self):\n",
    "        plt.title('FFT of RPY and rPPG signals')\n",
    "#         plt.plot(self.frame_vector, self.red_fft, color='red', label = 'Red')\n",
    "#         plt.plot(self.frame_vector, self.green_fft, color='green', label='Green')\n",
    "#         plt.plot(self.frame_vector, self.blue_fft, color='blue', label='Blue')\n",
    "#         plt.plot(self.frame_vector, self.rppg_fft, label = 'rPPG')\n",
    "#         plt.plot(self.frame_vector, self.roll_fft, color='cyan', label = 'Roll')\n",
    "#         plt.plot(self.frame_vector, self.pitch_fft, color='magenta', label='Pitch')\n",
    "#         plt.plot(self.frame_vector, self.yaw_fft, color='yellow', label='Yaw')\n",
    "        plt.plot(self.frame_vector[:50], self.rppg_fft[:50], label = 'rPPG')\n",
    "        plt.plot(self.frame_vector[:50], self.roll_fft[:50], color='cyan', label = 'Roll')\n",
    "        plt.plot(self.frame_vector[:50], self.pitch_fft[:50], color='magenta', label='Pitch')\n",
    "#         plt.plot(self.frame_vector[:50], self.yaw_fft[:50], color='yellow', label='Yaw')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        \n",
    "    def plot_combined_rpy_fft(self):\n",
    "        plt.title('Combined FFT of RPY signal')\n",
    "        plt.plot(self.frame_vector, self.combined_rpy_fft)\n",
    "        \n",
    "    def plot_rppg_rmns(self):\n",
    "        plt.title('FFT of rPPG signal after Rhythmic Noise Suppression')\n",
    "        plt.plot(self.frame_vector, self.rppg_fft_rmns)\n",
    "        \n",
    "    def plot_rppg_freq_filtered(self):\n",
    "        plt.title('rPPG after Frequency Filter')\n",
    "        plt.plot(self.frame_vector, self.rppg_freq_filtered)\n",
    "        \n",
    "    def draw_aam(self):\n",
    "        return\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful init\n",
      "[INFO] camera sensor warming up...\n"
     ]
    }
   ],
   "source": [
    "predictor_path = \"../detect-face-parts/shape_predictor_68_face_landmarks.dat\"\n",
    "fs = face_streamer(predictor_path)\n",
    "fs.stream(display_face_bb = False, display_landmarks = False, display_overlay = False, \n",
    "          display_pose_unstable = False, display_pose_stable =  False, display_pose_axis = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph RGB\n",
    "fs.plot_rgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph rPPG signals\n",
    "fs.plot_rppg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph RPY\n",
    "fs.plot_rpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph FFT of RGB and RPY signals signals\n",
    "fs.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the combined RPY FFT\n",
    "fs.plot_combined_rpy_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the rPPG FFT after Rhythmic Noise Suppression\n",
    "fs.plot_rppg_rmns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the rPPG after frequency filtering\n",
    "fs.plot_rppg_freq_filtered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from video \n",
    "# fs = face_streamer(predictor_path, filename = '/media/brandon/Seagate HDD/datasets/vicarPPG/Videos/01-mov.mp4')\n",
    "# fs.stream(display_face_bb = False, display_landmarks = False, display_overlay = True)\n",
    "# fs.plot_rgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs.plot_rpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(_path):\n",
    "    img = cv2.imread(_path,1)\n",
    "    while True:\n",
    "        cv2.imshow('image',img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            # do a bit of cleanup\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
