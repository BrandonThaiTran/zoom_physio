{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils.video import VideoStream, FileVideoStream\n",
    "from imutils import face_utils\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face streamer class \n",
    "class face_streamer:\n",
    "    def __init__(self, predictor_path, filename = None):\n",
    "        self.filename = filename\n",
    "        \n",
    "        # Initialize dlib's face detector (HOG-based)\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        \n",
    "        # Create landmark predictor.\n",
    "        self.predictor = dlib.shape_predictor(\"../detect-face-parts/shape_predictor_68_face_landmarks.dat\")\n",
    "        \n",
    "    def start_stream(self):\n",
    "        if self.filename:\n",
    "            self.vs = FileVideoStream(self.filename).start()\n",
    "        else:\n",
    "            self.vs = VideoStream(src=0).start()\n",
    "        print(\"[INFO] camera sensor warming up...\")\n",
    "        time.sleep(2.0)\n",
    "            \n",
    "    def end_stream(self):\n",
    "        # Do some cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        self.vs.stop()\n",
    "    \n",
    "    def stream(self, display_face_bb = False):\n",
    "        self.start_stream()\n",
    "        \n",
    "        # Loop and stream\n",
    "        while True:\n",
    "            # Read and resize frame\n",
    "            frame = self.vs.read()\n",
    "            frame = imutils.resize(frame, width=400)\n",
    "            # Grab faces bounding boxes\n",
    "            rects = self.get_face_bbs(frame)\n",
    "            \n",
    "            if display_face_bb:\n",
    "                frame = self.show_face_bbs(frame, rects)\n",
    "            \n",
    "#             # Extract only the face from the frame\n",
    "#             if track_face:\n",
    "#                 # extract the face\n",
    "#                 frame = self.extract_face(frame)\n",
    "                \n",
    "            # Show the frame\n",
    "            cv2.imshow(\"Frame\", frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            # If the `q` key was pressed, break from the loop.\n",
    "            if key == ord(\"q\"):\n",
    "                # Do some cleanup \n",
    "                self.end_stream()\n",
    "                del self.vs\n",
    "                break\n",
    "                \n",
    "    def get_face_bbs(self, frame):\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = self.detector(gray, 0)\n",
    "        return rects\n",
    "    \n",
    "    def show_face_bbs(self, frame, rects):\n",
    "        for rect in rects:\n",
    "            # compute the bounding box of the face and draw it on the\n",
    "            # frame\n",
    "            (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "            if show_box:\n",
    "                cv2.rectangle(frame, (bX, bY), (bW+bX, bH+bY), (0, 255, 0), 1)\n",
    "        return frame\n",
    "        \n",
    "    def extract_facial_landmarks(self, frame, show_box = True):\n",
    "        # Detect faces in grayscale frame\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        rects = self.detector(gray, 0)\n",
    "        # loop over the face detections\n",
    "        for rect in rects:\n",
    "            # compute the bounding box of the face and draw it on the\n",
    "            # frame\n",
    "            (bX, bY, bW, bH) = face_utils.rect_to_bb(rect)\n",
    "            if show_box:\n",
    "                cv2.rectangle(frame, (bX, bY), (bW+bX, bH+bY),\n",
    "                    (0, 255, 0), 1)\n",
    "#             # uncomment for landmarks\n",
    "#             # determine the facial landmarks for the face region, then\n",
    "#             # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "#             # array\n",
    "#             shape = self.predictor(gray, rect)\n",
    "#             shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "#             # loop over the (x, y)-coordinates for the facial landmarks\n",
    "#             # and draw each of them\n",
    "#             for (i, (x, y)) in enumerate(shape):\n",
    "#                 cv2.circle(frame, (x, y), 1, (0, 0, 255), -1)\n",
    "#                 cv2.putText(frame, str(i + 1), (x - 10, y - 10),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1)\n",
    "        return frame\n",
    "\n",
    "    def draw_aam(self):\n",
    "        return\n",
    "                \n",
    "# next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] camera sensor warming up...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'show_box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8063377cefa1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictor_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../detect-face-parts/shape_predictor_68_face_landmarks.dat\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_streamer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictor_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdisplay_face_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# del fs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dcb602289f72>\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, display_face_bb)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdisplay_face_bb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m                 \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_face_bbs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m#             # Extract only the face from the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-dcb602289f72>\u001b[0m in \u001b[0;36mshow_face_bbs\u001b[0;34m(self, frame, rects)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;31m# frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mbX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrect_to_bb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mshow_box\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbW\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbH\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'show_box' is not defined"
     ]
    }
   ],
   "source": [
    "predictor_path = \"../detect-face-parts/shape_predictor_68_face_landmarks.dat\"\n",
    "fs = face_streamer(predictor_path)\n",
    "fs.stream(display_face_bb = True)\n",
    "# del fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_face_detection(filename=None):\n",
    "    # To capture video from webcam.\n",
    "    if not _filename:\n",
    "        vs = VideoStream(src=0).start()\n",
    "    else:\n",
    "        # To use a video file as input \n",
    "        vs = FileVideoStream(filename).start()\n",
    "    time.sleep(2.0)\n",
    "\n",
    "    while True:\n",
    "        # grab frame and resize\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=400)\n",
    "        # grab the frame dimensions and convert it to a blob\n",
    "        (h, w) = frame.shape[:2]\n",
    "        blob = cv2.dnn.blobFromImage(cv2.resize(frame, (300, 300)), 1.0,\n",
    "            (300, 300), (104.0, 177.0, 123.0))\n",
    "        # pass the blob through the network and obtain the detections and\n",
    "        # predictions\n",
    "        net.setInput(blob)\n",
    "        detections = net.forward()\n",
    "        for i in range(0, detections.shape[2]):\n",
    "            # extract the confidence (i.e., probability) associated with the\n",
    "            # prediction\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            # filter out weak detections by ensuring the `confidence` is\n",
    "            # greater than the minimum confidence\n",
    "            if confidence < confidence_threshold:\n",
    "                continue\n",
    "            # compute the (x, y)-coordinates of the bounding box for the\n",
    "            # object\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            # draw the bounding box of the face along with the associated\n",
    "            # probability\n",
    "            text = \"{:.2f}%\".format(confidence * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY),\n",
    "                (0, 0, 255), 2)\n",
    "            cv2.putText(frame, text, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\", frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            # do a bit of cleanup\n",
    "            cv2.destroyAllWindows()\n",
    "            vs.stop()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(_path):\n",
    "    img = cv2.imread(_path,1)\n",
    "    while True:\n",
    "        cv2.imshow('image',img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            # do a bit of cleanup\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
