{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils.video import VideoStream, FileVideoStream\n",
    "from imutils import face_utils\n",
    "import cv2\n",
    "from time import time, sleep, perf_counter, process_time\n",
    "import numpy as np\n",
    "import dlib\n",
    "from collections import OrderedDict\n",
    "from pose_estimator import PoseEstimator\n",
    "from stabilizer import Stabilizer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from scipy.signal import butter, lfilter, find_peaks\n",
    "import pandas as pd\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face streamer class \n",
    "class face_streamer:\n",
    "    def __init__(self, predictor_path, filename = None):\n",
    "        self.filename = filename\n",
    "        \n",
    "        # Initialize dlib's face detector (HOG-based)\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        \n",
    "        # Create landmark predictor.\n",
    "        self.predictor = dlib.shape_predictor(predictor_path)\n",
    "        \n",
    "        self.facial_landmarks_idxs = OrderedDict([\n",
    "            (\"face\", (0, 26)),\n",
    "            (\"left_eye\", (37, 42)),\n",
    "            (\"right_eye\", (43, 48)),\n",
    "        ])\n",
    "        \n",
    "        # Colors to choose from\n",
    "        self.colors = [(19, 199, 109), (79, 76, 240), (230, 159, 23),\n",
    "                (168, 100, 168), (158, 163, 32),\n",
    "                (163, 38, 32), (180, 42, 220), (100, 150, 250)]\n",
    "        \n",
    "        # Define the width\n",
    "        self.width = 400\n",
    "        \n",
    "        # RGB signals\n",
    "        self.red_window = []\n",
    "        self.green_window = []\n",
    "        self.blue_window = []\n",
    "        self.red = []\n",
    "        self.green = []\n",
    "        self.blue = []\n",
    "        \n",
    "        # RPY signals\n",
    "        self.roll_window = []\n",
    "        self.pitch_window = []\n",
    "        self.yaw_window = []\n",
    "        self.roll = []\n",
    "        self.pitch = []\n",
    "        self.yaw = []\n",
    "        \n",
    "        # POS Signals\n",
    "        self.S1 = []\n",
    "        self.S2 = []\n",
    "        self.P = []\n",
    "        \n",
    "        # rPPG\n",
    "        self.rppg = []\n",
    "        \n",
    "        # fft signals\n",
    "        self.roll_fft = []\n",
    "        self.pitch_fft = []\n",
    "        self.yaw_fft = []\n",
    "        \n",
    "        self.rppg_fft = []\n",
    "        \n",
    "        # RMNS\n",
    "        self.combined_rpy_fft = []\n",
    "        self.rppg_fft_rmns = []\n",
    "        \n",
    "        # Freq filtered signals\n",
    "        self.rppg_filtered = []\n",
    "        \n",
    "        # After zmean\n",
    "        self.rppg_zmean = [0]\n",
    "        \n",
    "        self.frame_count = 0\n",
    "        self.num_shifts = 0\n",
    "        \n",
    "    def set_display(self, display_face_bb = False, display_landmarks = False, display_overlay = False, \n",
    "                    display_aam = False, display_pose_unstable = False, display_pose_stable = False, \n",
    "                    display_pose_axis = False):\n",
    "        # Update display parameters\n",
    "        self.display_face_bb = display_face_bb\n",
    "        self.display_landmarks = display_landmarks\n",
    "        self.display_overlay = display_overlay\n",
    "        self.display_aam = display_aam\n",
    "        self.display_pose_unstable = display_pose_unstable\n",
    "        self.display_pose_stable = display_pose_stable\n",
    "        self.display_pose_axis = display_pose_axis\n",
    "    \n",
    "    def stream(self, display_face_bb = False, display_landmarks = False, display_overlay = False, \n",
    "               display_aam = False, display_pose_unstable = False, display_pose_stable = False, \n",
    "               display_pose_axis = False):\n",
    "        \n",
    "        # Start the stream\n",
    "        self.start_stream()\n",
    "        \n",
    "        self.window_start_time = perf_counter()\n",
    "    \n",
    "        # Loop and stream\n",
    "        while True:\n",
    "            \n",
    "            # Process each frame \n",
    "            self.process_frame()\n",
    "                    \n",
    "            # Show the frame\n",
    "            cv2.imshow(\"Frame\", self.frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            # If the `q` key was pressed, break from the loop.\n",
    "            if key == ord(\"q\"):\n",
    "                # Process the signals\n",
    "                self.process_signals()\n",
    "                # Do some cleanup \n",
    "                self.end_stream()\n",
    "                break\n",
    "        \n",
    "    def start_stream(self):\n",
    "        print(\"[INFO] camera sensor warming up...\")\n",
    "        self.set_params()\n",
    "        sleep(1.0)\n",
    "            \n",
    "    def end_stream(self):\n",
    "        # Do some cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        self.vs.stop()\n",
    "        del self.vs\n",
    "        self.num_frames = len(self.red)\n",
    "        self.frame_vector = range(self.num_frames)\n",
    "        self.rppg_frame_vector = range(len(self.rppg_zmean))\n",
    "        self.calculate_output()\n",
    "        \n",
    "    def set_params(self):\n",
    "        # Start default camera\n",
    "        if self.filename:\n",
    "            self.vs = FileVideoStream(self.filename).start()\n",
    "        else:\n",
    "            self.vs = VideoStream(src=0).start()\n",
    "\n",
    "        # Number of frames to capture\n",
    "        num_frames = 60\n",
    "\n",
    "        print(\"Capturing {0} frames\".format(num_frames))\n",
    "\n",
    "        # Start time\n",
    "        start = time()\n",
    "            \n",
    "        # Grab a few frames\n",
    "        for i in range(0, num_frames):\n",
    "            frame = self.vs.read()\n",
    "            frame = imutils.resize(frame, width = self.width)\n",
    "\n",
    "        # End time\n",
    "        end = time()\n",
    "\n",
    "        # Time elapsed\n",
    "        seconds = end - start\n",
    "        print (f\"Time taken to capture {num_frames}: {seconds} seconds\")\n",
    "\n",
    "        # Calculate frames per second\n",
    "        # Round to 30 or 60\n",
    "        fps  = num_frames / seconds\n",
    "        possible_rates = [30, 60] # these are the possible rates that we can round to\n",
    "        self.fps = possible_rates[min(range(len(possible_rates)), key = lambda i: abs(possible_rates[i]-fps))] \n",
    "        print(\"Estimated frames per second : {0}\".format(self.fps))\n",
    "\n",
    "        # Find image dimensions and make the stablizer\n",
    "        frame = imutils.resize(self.vs.read(), width=self.width)\n",
    "        self.height, _, _ = frame.shape\n",
    "        self.pose_estimator = PoseEstimator(img_size=(self.height, self.width))\n",
    "        self.pose_stabilizers = [Stabilizer(state_num=2, measure_num=1, cov_process=0.1, cov_measure=0.1) \n",
    "                            for _ in range(6)]\n",
    "        \n",
    "        # Set the frame limit \n",
    "        if self.fps == 30:\n",
    "            self.frame_limit = 256/4\n",
    "        else: \n",
    "            self.frame_limit = 512/4\n",
    "            \n",
    "        # Time limit\n",
    "        self.time_limit = self.frame_limit/self.fps\n",
    "        print(f'Time limit: {self.time_limit} Frame limit: {self.frame_limit}')\n",
    "            \n",
    "        self.frame_limit_vector = range(int(self.frame_limit))\n",
    "        \n",
    "    # Processes the signals when the frame limit has been reached\n",
    "    def process_signals(self):\n",
    "        self.resample_signals()\n",
    "        self.apply_pos()\n",
    "        self.apply_signal_filtering()\n",
    "        self.apply_post_processing()\n",
    "        self.append_window_signals()\n",
    "        \n",
    "    # Processes the frame by updating numerical values and drawing on it (if specified)\n",
    "    def process_frame(self):\n",
    "        # Process and append the signals if the frame_limit is reached \n",
    "#         if self.frame_count >= self.frame_limit:\n",
    "#             self.process_signals()\n",
    "        # Process and append the signals if the time limit is reached \n",
    "        if perf_counter() - self.window_start_time >= self.time_limit:\n",
    "            self.process_signals()\n",
    "            \n",
    "        self.find_face()\n",
    "        self.loop_faces()\n",
    "        self.frame_count += 1\n",
    "    \n",
    "    # Finds faces in the image \n",
    "    def find_face(self):\n",
    "        # Read and resize the frame\n",
    "        self.frame = self.vs.read()\n",
    "        self.frame = imutils.resize(self.vs.read(), width=self.width)\n",
    "        # Get grayscale image and extract the bounding boxes with the detector \n",
    "        self.gray = cv2.cvtColor(self.frame, cv2.COLOR_BGR2GRAY)\n",
    "        self.rects = self.detector(self.gray, 0)\n",
    "    \n",
    "    # Loops over the faces to update values and to draw on the frame\n",
    "    def loop_faces(self):\n",
    "        for rect in self.rects:\n",
    "            # Get the bounding box \n",
    "            (self.bX, self.bY, self.bW, self.bH) = face_utils.rect_to_bb(rect)\n",
    "            # Determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array.\n",
    "            self.shape = face_utils.shape_to_np(self.predictor(self.gray, rect))\n",
    "            # Set the facial points for the roi\n",
    "            self.set_face_points()\n",
    "            # Apply the aam\n",
    "            self.apply_aam()\n",
    "            # Get RGB values\n",
    "            self.update_rgb() \n",
    "            # Try pose estimation\n",
    "            self.pose = self.pose_estimator.solve_pose_by_68_points(\n",
    "                self.shape.astype('float'))\n",
    "            # Stabilize the pose\n",
    "            self.stablize_pose()\n",
    "            # Update RPY values \n",
    "            self.update_rpy()\n",
    "            # If a face is found, draw on the face\n",
    "            if self.shape.any():\n",
    "                self.draw_frame()\n",
    "                \n",
    "    def update_rgb(self):\n",
    "        self.red_window.append(np.sum(self.aam[:,:,0])/ self.num_aam_pixels)\n",
    "        self.green_window.append(np.sum(self.aam[:,:,1])/ self.num_aam_pixels)\n",
    "        self.blue_window.append(np.sum(self.aam[:,:,2])/ self.num_aam_pixels)\n",
    "\n",
    "    def update_rpy(self):\n",
    "        self.roll_window.append(self.steady_pose[0][2] * -1)\n",
    "        self.pitch_window.append(self.steady_pose[0][1])\n",
    "        self.yaw_window.append(self.steady_pose[0][0])\n",
    "    \n",
    "    # Applies the AAM by turning all cells outside of the face to 0\n",
    "    def apply_aam(self):\n",
    "        self.aam = np.zeros_like(self.frame)\n",
    "        \n",
    "        # Initialize masks \n",
    "        feature_mask = np.zeros((self.frame.shape[0], self.frame.shape[1]))  \n",
    "        l_eye_mask = np.zeros((self.frame.shape[0], self.frame.shape[1]))  \n",
    "        r_eye_mask = np.zeros((self.frame.shape[0], self.frame.shape[1]))  \n",
    "        custom_mask = np.zeros((self.frame.shape[0], self.frame.shape[1]))\n",
    "        \n",
    "        # Define hulls for the facial components \n",
    "        hull = cv2.convexHull(self.face_points)\n",
    "        hull_left_eye = cv2.convexHull(self.left_eye_points)\n",
    "        hull_right_eye = cv2.convexHull(self.right_eye_points)\n",
    "        custom_hull = cv2.convexHull(self.custom_points)\n",
    "        \n",
    "        # Fill the convex hulls for 1s, which mean that that pixel location is in the ROI.\n",
    "        feature_mask = cv2.fillConvexPoly(feature_mask, hull, 1).astype(np.bool)\n",
    "        l_eye_mask = cv2.fillConvexPoly(l_eye_mask, hull_left_eye, 1).astype(np.bool)\n",
    "        r_eye_mask = cv2.fillConvexPoly(r_eye_mask, hull_right_eye, 1).astype(np.bool)\n",
    "        custom_mask = cv2.fillConvexPoly(custom_mask, custom_hull, 1).astype(np.bool)\n",
    "        \n",
    "        # Use XOR to make a boolean mask of pixels inside our ROI\n",
    "        final_mask = np.logical_xor(feature_mask, l_eye_mask)\n",
    "        final_mask = np.logical_xor(final_mask, r_eye_mask)\n",
    "        \n",
    "        custom_final_mask = np.logical_xor(custom_mask, l_eye_mask)\n",
    "        self.custom_final_mask = np.logical_xor(custom_final_mask, r_eye_mask)\n",
    "        \n",
    "        # Final AAM\n",
    "        self.aam[self.custom_final_mask] = self.frame[self.custom_final_mask]\n",
    "        self.num_aam_pixels = np.sum(self.custom_final_mask)        \n",
    "    \n",
    "    # Apply POS to combine rgb signal in to rPPG signal\n",
    "    def apply_pos(self):\n",
    "        self.red_window = self.normalize_signal(self.red_window)\n",
    "        self.green_window = self.normalize_signal(self.green_window)\n",
    "        self.blue_window = self.normalize_signal(self.blue_window)\n",
    "        C = np.array([self.red_window, self.green_window, self.blue_window])\n",
    "        mean_color = np.mean(C, axis=1)\n",
    "        diag_mean_color = np.diag(mean_color)\n",
    "        diag_mean_color_inv = np.linalg.inv(diag_mean_color)\n",
    "        Cn = np.matmul(diag_mean_color_inv,C)\n",
    "        projection_matrix = np.array([[0,1,-1],[-2,1,1]])\n",
    "        self.S_window = np.matmul(projection_matrix,Cn)\n",
    "        std = np.array([1,np.std(self.S_window[0,:])/np.std(self.S_window[1,:])])\n",
    "        self.P_window = np.matmul(std,self.S_window)\n",
    "        self.rppg_window = self.P_window-np.mean(self.P_window)\n",
    "    \n",
    "    def apply_signal_filtering(self):\n",
    "        self.apply_rmns()\n",
    "        self.apply_wnb_filter()\n",
    "        \n",
    "    # empircally play with the normalizing in the freq domain\n",
    "    # normalize RPY and RGB \n",
    "    # RPY -45 and +45 -> []\n",
    "    # RPY to freq -> normalize -> combine (average)\n",
    "    # todo - fix scale of rpy_fft signal\n",
    "    # Applies Rhythmic Motion Noise Suppresion\n",
    "    def apply_rmns(self):\n",
    "        # Method 1: 1) temporal normalize RPY 2) FFT of normalized signals 3) combine\n",
    "        # Normalize RPY signals\n",
    "        self.roll_window = self.normalize_signal(self.roll_window)\n",
    "        self.pitch_window = self.normalize_signal(self.pitch_window)\n",
    "        self.yaw_window = self.normalize_signal(self.yaw_window)\n",
    "        # Find fft of RPY and rPPG signals\n",
    "        self.rppg_fft_window = np.abs(fft(self.rppg_window))\n",
    "        self.roll_fft_window = np.abs(fft(self.roll_window))\n",
    "        self.pitch_fft_window = np.abs(fft(self.pitch_window))\n",
    "        self.yaw_fft_window = np.abs(fft(self.yaw_window))\n",
    "        # Combine rpy_fft signals via averaging (divide by 3)\n",
    "        self.combined_rpy_fft_window = (self.roll_fft_window + self.pitch_fft_window + self.yaw_fft_window)/3\n",
    "        # Normalization\n",
    "#         self.combined_rpy_fft_window = self.combined_rpy_fft_window/np.mean(self.combined_rpy_fft_window)\n",
    "        \n",
    "#         # Method 2: 1) FFT 2) normalize FFT 3) combine\n",
    "#         # take FFT\n",
    "#         self.rppg_fft_window = np.abs(fft(self.rppg_window))\n",
    "#         self.roll_fft_window = np.abs(fft(self.roll_window))\n",
    "#         self.pitch_fft_window = np.abs(fft(self.pitch_window))\n",
    "#         self.yaw_fft_window = np.abs(fft(self.yaw_window))\n",
    "#         # Normalize\n",
    "#         self.roll_fft_window = self.normalize_signal(self.roll_fft_window)\n",
    "#         self.pitch_fft_window = self.normalize_signal(self.pitch_fft_window)\n",
    "#         self.yaw_fft_window = self.normalize_signal(self.yaw_fft_window)\n",
    "#         # Combine rpy_fft signals via averaging (divide by 3)\n",
    "#         self.combined_rpy_fft_window = (self.roll_fft_window + self.pitch_fft_window + self.yaw_fft_window)/3\n",
    "        \n",
    "#         # Method 3: 1) FFT 2) combine 3)normalize\n",
    "#         # take FFT\n",
    "#         self.rppg_fft_window = np.abs(fft(self.rppg_window))\n",
    "#         self.roll_fft_window = np.abs(fft(self.roll_window))\n",
    "#         self.pitch_fft_window = np.abs(fft(self.pitch_window))\n",
    "#         self.yaw_fft_window = np.abs(fft(self.yaw_window))\n",
    "#         # Combine rpy_fft signals via averaging (divide by 3)\n",
    "#         self.combined_rpy_fft_window = self.normalize_signal((self.roll_fft_window + self.pitch_fft_window + self.yaw_fft_window)/3)\n",
    "        \n",
    "        # Apply RMNS\n",
    "#         self.rppg_fft_rmns_window = self.rppg_fft_window - self.combined_rpy_fft_window\n",
    "        # Without RMNS\n",
    "        self.rppg_fft_rmns_window = self.rppg_fft_window\n",
    "        \n",
    "    # TODO - Tune \n",
    "    def apply_wnb_filter(self):\n",
    "        bandwidth = .2\n",
    "        nyq = 0.5 * self.fps\n",
    "        # Find max freq\n",
    "        max_freq = self.find_highest_freq(self.rppg_fft_rmns_window)\n",
    "        # Make band\n",
    "        freq_band = [(max_freq + i*bandwidth/2)/nyq for i in [-1, 1]]\n",
    "#         print(freq_band)\n",
    "        # Butterworth filter\n",
    "        N = 5 # butterworth signal order\n",
    "        b, a = butter(N, freq_band, btype='bandpass')\n",
    "        # use bandpass filter\n",
    "        self.rppg_filtered_window = lfilter(b, a, self.rppg_fft_rmns_window)\n",
    "#         self.rppg_freq_filtered_window = np.abs(ifft(self.rppg_fft_rmns_window))\n",
    "    \n",
    "    # Finds highest frequency in hz\n",
    "    def find_highest_freq(self, signal):\n",
    "        freq_hz = abs(fftfreq(signal.shape[0]) * self.fps)\n",
    "        max_idx = np.argmax(signal)\n",
    "        max_freq = freq_hz[max_idx]\n",
    "        return max_freq\n",
    "        \n",
    "    def apply_post_processing(self):\n",
    "        self.rppg_zmean_window = (self.rppg_filtered_window - np.mean(self.rppg_filtered_window))/np.std(self.rppg_filtered_window)\n",
    "        self.rppg_len = len(self.rppg_zmean)\n",
    "        # determine number of frames to shift \n",
    "        seg_t = self.time_limit / 2\n",
    "        l = 1 # num frames to shift\n",
    "#         l = int(self.fps * seg_t)\n",
    "#         self.num_shifts += 1\n",
    "#         print('n shift', self.num_shifts)\n",
    "#         self.rppg_zmean_window[:l] = [rppg + self.rppg_zmean[self.rppg_len-l+i] for (i,rppg) in enumerate(self.rppg_zmean_window[:l])]\n",
    "#         self.rppg_zmean = [rppg/self.num_shifts for rppg in self.rppg_zmean]\n",
    "#         self.rppg_zmean = self.rppg_zmean[:-1*l]\n",
    "        self.rppg_zmean.extend(self.rppg_zmean_window)\n",
    "        self.rppg_len = len(self.rppg_zmean)\n",
    "#         H[t:t+l] = H[t:t+l] +  (P-np.mean(P))\n",
    "\n",
    "    def stablize_pose(self):\n",
    "        self.steady_pose = []\n",
    "        pose_np = np.array(self.pose).flatten()\n",
    "        for value, ps_stb in zip(pose_np, self.pose_stabilizers):\n",
    "            ps_stb.update([value])\n",
    "            self.steady_pose.append(ps_stb.state[0])\n",
    "        self.steady_pose = np.reshape(self.steady_pose, (-1, 3))\n",
    "    \n",
    "    def set_face_points(self):\n",
    "        # x,y locations of the facial landmarks\n",
    "        self.face_points = self.shape[self.facial_landmarks_idxs['face'][0]:self.facial_landmarks_idxs['face'][1]]\n",
    "        self.left_eye_points = self.shape[self.facial_landmarks_idxs['left_eye'][0]:self.facial_landmarks_idxs['left_eye'][1]]\n",
    "        self.right_eye_points = self.shape[self.facial_landmarks_idxs['right_eye'][0]:self.facial_landmarks_idxs['right_eye'][1]]\n",
    "\n",
    "        # Define custom ROI\n",
    "        custom_roi = [0,1,2,3,13,14,15,16,17,18,19,20,21,22,23,24,25,26,33]\n",
    "        avg_1 = np.asarray([np.mean([self.shape[3][0], self.shape[48][0]],dtype=np.int64), np.mean([self.shape[3][1],self.shape[48][1]],dtype=np.int64)])\n",
    "        avg_2 = np.asarray([np.mean([self.shape[13][0], self.shape[54][0]],dtype=np.int64), np.mean([self.shape[13][1],self.shape[54][1]])],dtype=np.int64)\n",
    "        points = [self.shape[i] for i in custom_roi]\n",
    "        points.extend([avg_1, avg_2])\n",
    "        self.custom_points = np.asarray(points)\n",
    "        \n",
    "    # normalize RGB signal by dividing by mean\n",
    "    def normalize_signal(self, signal):\n",
    "        signal = signal/np.mean(signal)\n",
    "        return signal\n",
    "    \n",
    "    def resample_signals(self):\n",
    "        frame_collected_vector = range(len(self.red_window))\n",
    "        # RGB\n",
    "        self.red_window = np.interp(self.frame_limit_vector, frame_collected_vector,self.red_window)\n",
    "        self.green_window = np.interp(self.frame_limit_vector, frame_collected_vector,self.green_window)\n",
    "        self.blue_window = np.interp(self.frame_limit_vector, frame_collected_vector,self.blue_window)\n",
    "        \n",
    "        # RPY\n",
    "        self.roll_window = np.interp(self.frame_limit_vector, frame_collected_vector,self.roll_window)\n",
    "        self.pitch_window = np.interp(self.frame_limit_vector, frame_collected_vector,self.pitch_window)\n",
    "        self.yaw_window = np.interp(self.frame_limit_vector, frame_collected_vector,self.yaw_window)\n",
    "        \n",
    "    def append_window_signals(self):\n",
    "        print('append called')\n",
    "        # RGB signals\n",
    "        self.red.extend(self.red_window)\n",
    "        self.green.extend(self.green_window)\n",
    "        self.blue.extend(self.blue_window)\n",
    "        \n",
    "        # RPY signals\n",
    "        self.roll.extend(self.roll_window)\n",
    "        self.pitch.extend(self.pitch_window)\n",
    "        self.yaw.extend(self.yaw_window)\n",
    "        \n",
    "        # POS Signals\n",
    "        self.S1.extend(self.S_window[0,:])\n",
    "        self.S2.extend(self.S_window[1,:])\n",
    "        self.P.extend(self.P_window)\n",
    "        \n",
    "        # rPPG\n",
    "        self.rppg.extend(self.rppg_window)\n",
    "        \n",
    "        # fft signals\n",
    "        self.roll_fft.extend(self.roll_fft_window)\n",
    "        self.pitch_fft.extend(self.pitch_fft_window)\n",
    "        self.yaw_fft.extend(self.yaw_fft_window)\n",
    "        \n",
    "        self.rppg_fft.extend(self.rppg_fft_window)\n",
    "        \n",
    "        # RMNS\n",
    "        self.combined_rpy_fft.extend(self.combined_rpy_fft_window)\n",
    "        self.rppg_fft_rmns.extend(self.rppg_fft_rmns_window)\n",
    "        \n",
    "        # Freq filtered signals\n",
    "        self.rppg_filtered.extend(self.rppg_filtered_window)\n",
    "        \n",
    "        # Zero mean rPPG\n",
    "#         self.rppg_zmean.extend(self.rppg_zmean_window)\n",
    "        \n",
    "        self.reset_window_signals()\n",
    "        \n",
    "    def reset_window_signals(self):\n",
    "        # Frame count\n",
    "#         print('frame count: ', self.frame_count)\n",
    "        self.frame_count = 0\n",
    "        # Time\n",
    "#         print('window time: ', perf_counter() - self.window_start_time)\n",
    "        self.window_start_time = perf_counter()\n",
    "        # RGB signals\n",
    "        self.red_window = []\n",
    "        self.green_window = []\n",
    "        self.blue_window = []\n",
    "        \n",
    "        # RPY signals\n",
    "        self.roll_window = []\n",
    "        self.pitch_window = []\n",
    "        self.yaw_window = []\n",
    "        \n",
    "    def calculate_output(self):\n",
    "        # Find the peaks\n",
    "        detected_peak_idxs = find_peaks(self.rppg_zmean, distance = 20)[0]\n",
    "        self.time_vector = [frame * (1/self.fps) for frame in range(self.rppg_len)] # in seconds\n",
    "        self.peaks = [self.time_vector[detected_peak_idx] for detected_peak_idx in detected_peak_idxs]\n",
    "        # IBIs\n",
    "        self.IBIs = self.find_IBIs(self.peaks)\n",
    "        # hr and HRV\n",
    "        self.hr = self.find_hr(self.IBIs)\n",
    "        self.rmssd, self.sdnn = self.find_hrv(self.IBIs)\n",
    "        \n",
    "    def find_IBIs(self, peaks):\n",
    "        IBIs = []\n",
    "        for i in range(len(peaks)-1):\n",
    "            IBIs.append(peaks[i+1] - peaks[i])\n",
    "        return IBIs\n",
    "#         return [IBI/1000 for IBI in IBIs]\n",
    "\n",
    "    def find_hr(self, IBIs):\n",
    "        IBI_mean = np.average(IBIs)\n",
    "        hr = 1/IBI_mean * 60\n",
    "        return hr\n",
    "\n",
    "    def find_hrv(self, IBIs):\n",
    "        rmssd = self.find_rmssd(IBIs) * 1000 \n",
    "        sdnn = self.find_sdnn(IBIs) * 1000 \n",
    "        return rmssd, sdnn\n",
    "\n",
    "    def find_rmssd(self, IBIs):\n",
    "        N = len(IBIs)\n",
    "        ssd = 0 \n",
    "        for i in range(N-1):\n",
    "            ssd += (IBIs[i+1] - IBIs[i])**2\n",
    "        rmssd = np.sqrt(ssd/(N-1))\n",
    "        return rmssd\n",
    "\n",
    "    def find_sdnn(self, IBIs):\n",
    "        sdnn = np.std(IBIs)\n",
    "        return sdnn\n",
    "        \n",
    "    def draw_frame(self):\n",
    "        if self.display_aam:\n",
    "            self.draw_overlay()\n",
    "        # Display bounding box if true\n",
    "        if self.display_face_bb:\n",
    "            self.draw_face_bb()\n",
    "        # Display facial landmarks if true\n",
    "        if self.display_landmarks:\n",
    "            self.draw_landmarks()\n",
    "        # Display the landmark overlay if true\n",
    "        if self.display_overlay:\n",
    "            self.draw_overlay()\n",
    "        # Display the pose if true\n",
    "        if self.display_pose_unstable or self.display_pose_stable:\n",
    "            self.draw_pose()\n",
    "        # Display the pose axis if true\n",
    "        if self.display_pose_axis:\n",
    "            self.draw_pose_axis()\n",
    "                        \n",
    "    def draw_face_bb(self):\n",
    "        # Draw the bounding box on the frame\n",
    "        cv2.rectangle(self.frame, (self.bX, self.bY), \n",
    "                      (self.bW+self.bX, self.bH+self.bY), (0, 255, 0), 1)\n",
    "    \n",
    "    def draw_landmarks(self):\n",
    "        for (name, (i, j)) in self.facial_landmarks_idxs.items():\n",
    "            # Loop over the subset of facial landmarks, drawing the specific face part\n",
    "            for (x, y) in self.shape[i:j]:\n",
    "                cv2.circle(self.frame, (x, y), 1, (0, 0, 255), -1)\n",
    "    \n",
    "    # Displays the overlay of the landmarks \n",
    "    def draw_overlay(self, alpha=0.75):\n",
    "        # Apply the transparent overlay\n",
    "#         cv2.addWeighted(self.aam, alpha, self.frame, 1 - alpha, 0,self.frame)\n",
    "        # apply a color\n",
    "        self.frame[self.custom_final_mask] = self.colors[0]\n",
    "    \n",
    "    def draw_pose(self):\n",
    "        # Display the initial pose annotation if true\n",
    "        if self.display_pose_unstable:\n",
    "            self.pose_estimator.draw_annotation_box(\n",
    "                self.frame, self.pose[0], self.pose[1], \n",
    "                color=(255, 128, 128))\n",
    "        # Display the stablized pose annotation if true\n",
    "        if self.display_pose_stable:\n",
    "            self.pose_estimator.draw_annotation_box(\n",
    "                self.frame, self.steady_pose[0], self.steady_pose[1], \n",
    "                color=(128, 255, 128))\n",
    "        \n",
    "    def draw_pose_axis(self):\n",
    "        self.pose_estimator.draw_axis(self.frame, \n",
    "                                      self.steady_pose[0], self.steady_pose[1])\n",
    "        \n",
    "    def plot_rgb(self):\n",
    "        plt.title('Normalized RGB values as a function of frames')\n",
    "        plt.plot(self.frame_vector, self.red, color='red', label = 'Red')\n",
    "        plt.plot(self.frame_vector, self.green, color='green', label='Green')\n",
    "        plt.plot(self.frame_vector, self.blue, color='blue', label='Blue')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        \n",
    "    def plot_projected_signal(self):\n",
    "        plt.title('Projected Signals')\n",
    "        plt.plot(self.frame_vector, self.S1)\n",
    "        plt.plot(self.frame_vector, self.S2)\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "        \n",
    "    def plot_rppg(self):\n",
    "        plt.title('rPPG signal')\n",
    "        plt.plot(self.frame_vector, self.rppg)\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "    \n",
    "    def plot_rpy(self):\n",
    "        plt.title('RPY values as a function of frames')\n",
    "        plt.plot(self.frame_vector, self.roll, color='cyan', label = 'Roll')\n",
    "        plt.plot(self.frame_vector, self.pitch, color='magenta', label='Pitch')\n",
    "        plt.plot(self.frame_vector, self.yaw, color='yellow', label='Yaw')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        \n",
    "    def plot_fft(self):\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title('FFT of RPY signals')\n",
    "        plt.plot(self.frame_vector, self.roll_fft, color='cyan', label = 'Roll')\n",
    "        plt.plot(self.frame_vector, self.pitch_fft, color='magenta', label='Pitch')\n",
    "        plt.plot(self.frame_vector, self.yaw_fft, color='yellow', label='Yaw')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title('FFT rPPG signals')\n",
    "        plt.plot(self.frame_vector, self.rppg_fft, label = 'rPPG')\n",
    "        \n",
    "    def plot_combined_rpy_fft(self):\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title('Combined FFT of RPY signal')\n",
    "        plt.plot(self.frame_vector, self.combined_rpy_fft)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title('Combined FFT of rPPG signal')\n",
    "        plt.plot(self.frame_vector, self.rppg_fft)\n",
    "        \n",
    "    def plot_rppg_rmns(self):\n",
    "        plt.title('FFT of rPPG signal after Rhythmic Noise Suppression')\n",
    "        # freq domain \n",
    "        plt.plot(self.frame_vector, self.rppg_fft_rmns)\n",
    "\n",
    "    def plot_rppg_filtered(self):\n",
    "        plt.title('rPPG after Frequency Filter')\n",
    "        plt.plot(self.frame_vector, self.rppg_filtered)\n",
    "        \n",
    "    def plot_rppg_zmean(self):\n",
    "        plt.title('rPPG with zero mean')\n",
    "        plt.plot(self.rppg_frame_vector,self.rppg_zmean)\n",
    "        \n",
    "    def plot_peaks(self):\n",
    "        plt.plot(self.time_vector, self.rppg_zmean)\n",
    "        plt.xlabel('Time (ms)')\n",
    "        for peak in self.peaks:\n",
    "            plt.axvline(x = peak, color = 'r')\n",
    "        print(f'HR (BPM): {self.hr}')\n",
    "        print(f'HRV RMSSD (ms) {self.rmssd} SDNN: {self.sdnn}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] camera sensor warming up...\n",
      "Capturing 60 frames\n",
      "Time taken to capture 60: 0.23225069046020508 seconds\n",
      "Estimated frames per second : 60\n",
      "successful init\n",
      "Time limit: 2.1333333333333333 Frame limit: 128.0\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n",
      "append called\n"
     ]
    }
   ],
   "source": [
    "predictor_path = \"../models/shape_predictor_68_face_landmarks.dat\"\n",
    "filename = '/media/brandon/Seagate HDD/datasets/vicarPPG/Videos/01-base.mp4'\n",
    "# filename = None\n",
    "fs = face_streamer(predictor_path, filename = filename)\n",
    "# If display_aam is true, this is all you will see\n",
    "fs.set_display(display_face_bb = False, display_landmarks = True, display_overlay = False, display_aam = True,\n",
    "               display_pose_unstable = False, display_pose_stable = True, display_pose_axis = True)\n",
    "fs.stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph RGB\n",
    "fs.plot_rgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projected signal\n",
    "fs.plot_projected_signal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P \n",
    "plt.title('P signal')\n",
    "plt.plot(fs.frame_vector, fs.P)\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph rPPG signals\n",
    "fs.plot_rppg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph RPY\n",
    "fs.plot_rpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph FFT of RGB and RPY signals signals\n",
    "fs.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graph the combined RPY FFT\n",
    "fs.plot_combined_rpy_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the rPPG FFT after Rhythmic Noise Suppression\n",
    "fs.plot_rppg_rmns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graph the rPPG after frequency filtering\n",
    "fs.plot_rppg_filtered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the rPPG after zmean\n",
    "fs.plot_rppg_zmean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs.plot_peaks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-cleaned PPG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/media/brandon/Seagate HDD/datasets/vicarPPG/GroundTruth/PPG/Cleaned/01-base PPG.csv')\n",
    "N = df['Signal'].values.shape[0]\n",
    "stop = N - 1\n",
    "stop = 500\n",
    "signal = df['Signal'][:stop].values\n",
    "time = df['Time'][:stop].values\n",
    "plt.plot(time, signal)\n",
    "plt.xlabel('Time (ms)')\n",
    "peaks = [df['Time'][idx] for idx, element in enumerate(df['Peaks']) if element == 1]\n",
    "for peak in peaks:\n",
    "    if peak >= df['Time'][stop]:\n",
    "        break\n",
    "    plt.axvline(x = peak, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(peaks[:stop])\n",
    "detected_peak_idxs = find_peaks(df['Signal'].values, distance = 20)[0][:stop]\n",
    "print(detected_peak_idxs)\n",
    "detected_peaks = [df['Time'][idx] for idx in detected_peak_idxs]\n",
    "# print(detected_peaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(time, signal)\n",
    "plt.xlabel('Time (ms)')\n",
    "peaks = [df['Time'][idx] for idx, element in enumerate(df['Peaks']) if element == 1]\n",
    "# detected_peaks = [peaks[idx] for idx in peaks[find_peaks(df['Signal'].values)[:stop]][0]]\n",
    "for peak in detected_peaks:\n",
    "    if peak >= df['Time'][stop]:\n",
    "        break\n",
    "    plt.axvline(x = peak, color = 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rppg = [0]\n",
    "for i in range(2):\n",
    "    rppg = rppg[:-1]\n",
    "    rppg.extend(np.random.randn(256))\n",
    "print(len(rppg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_IBIs(peaks):\n",
    "    IBIs = []\n",
    "    for i in range(len(peaks)-1):\n",
    "        IBIs.append(peaks[i+1] - peaks[i])\n",
    "    return [IBI/1000 for IBI in IBIs]\n",
    "\n",
    "def find_hr(peaks):\n",
    "    IBIs = find_IBIs(peaks)\n",
    "    IBI_mean = np.average(IBIs)\n",
    "    hr = 1/IBI_mean * 60\n",
    "    return hr\n",
    "\n",
    "def find_hrv(peaks):\n",
    "    IBIs = find_IBIs(peaks)\n",
    "    hrv = find_rmssd(IBIs) * 1000\n",
    "    sdnn = find_sdnn(IBIs)\n",
    "    return hrv, sdnn\n",
    "\n",
    "def find_rmssd(IBIs):\n",
    "    N = len(IBIs)\n",
    "    ssd = 0 \n",
    "    for i in range(N-1):\n",
    "        ssd += (IBIs[i+1] - IBIs[i])**2\n",
    "    rmssd = np.sqrt(ssd/(N-1))\n",
    "    return rmssd\n",
    "\n",
    "def find_sdnn(IBIs):\n",
    "    sdnn = np.std(IBIs) * 1000\n",
    "    return sdnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_hr(peaks))\n",
    "print(find_hrv(peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(find_hr(detected_peaks))\n",
    "print(find_hrv(detected_peaks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
