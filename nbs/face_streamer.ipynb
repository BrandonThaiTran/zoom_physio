{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imutils\n",
    "from imutils.video import VideoStream, FileVideoStream\n",
    "from imutils import face_utils\n",
    "import cv2\n",
    "import time\n",
    "import numpy as np\n",
    "import dlib\n",
    "from collections import OrderedDict\n",
    "from pose_estimator import PoseEstimator\n",
    "from stabilizer import Stabilizer\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, ifft\n",
    "import pandas as pd\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(path = None, img = None):\n",
    "    if path:\n",
    "        img = cv2.imread(path,1)\n",
    "    while True:\n",
    "        cv2.imshow('image',img)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            # do a bit of cleanup\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face streamer class \n",
    "class face_streamer:\n",
    "    def __init__(self, predictor_path, filename = None):\n",
    "        self.filename = filename\n",
    "        \n",
    "        # Initialize dlib's face detector (HOG-based)\n",
    "        self.detector = dlib.get_frontal_face_detector()\n",
    "        \n",
    "        # Create landmark predictor.\n",
    "        self.predictor = dlib.shape_predictor(predictor_path)\n",
    "        \n",
    "        self.facial_landmarks_idxs = OrderedDict([\n",
    "            (\"face\", (0, 26)),\n",
    "            (\"left_eye\", (37, 42)),\n",
    "            (\"right_eye\", (43, 48)),\n",
    "        ])\n",
    "        \n",
    "        # Colors to choose from\n",
    "        self.colors = [(19, 199, 109), (79, 76, 240), (230, 159, 23),\n",
    "                (168, 100, 168), (158, 163, 32),\n",
    "                (163, 38, 32), (180, 42, 220), (100, 150, 250)]\n",
    "        \n",
    "        # Define the width\n",
    "        self.width = 400\n",
    "        \n",
    "        # RGB signals\n",
    "        self.red_window = []\n",
    "        self.green_window = []\n",
    "        self.blue_window = []\n",
    "        self.red = []\n",
    "        self.green = []\n",
    "        self.blue = []\n",
    "        \n",
    "        # RPY signals\n",
    "        self.roll_window = []\n",
    "        self.pitch_window = []\n",
    "        self.yaw_window = []\n",
    "        self.roll = []\n",
    "        self.pitch = []\n",
    "        self.yaw = []\n",
    "        \n",
    "        # POS Signals\n",
    "        self.S1 = []\n",
    "        self.S2 = []\n",
    "        self.P = []\n",
    "        \n",
    "        # rPPG\n",
    "        self.rppg = []\n",
    "        \n",
    "        # fft signals\n",
    "        self.roll_fft = []\n",
    "        self.pitch_fft = []\n",
    "        self.yaw_fft = []\n",
    "        \n",
    "        self.rppg_fft = []\n",
    "        \n",
    "        # RMNS\n",
    "        self.combined_rpy_fft = []\n",
    "        self.rppg_fft_rmns = []\n",
    "        \n",
    "        # Freq filtered signals\n",
    "        self.rppg_freq_filtered = []\n",
    "        \n",
    "        self.frame_count = 0\n",
    "        \n",
    "    def stream(self, display_face_bb = False, display_landmarks = False, display_overlay = False, \n",
    "               display_aam = False, display_pose_unstable = False, display_pose_stable = False, \n",
    "               display_pose_axis = False):\n",
    "        # Update display parameters\n",
    "        self.display_face_bb = display_face_bb\n",
    "        self.display_landmarks = display_landmarks\n",
    "        self.display_overlay = display_overlay\n",
    "        self.display_aam = display_aam\n",
    "        self.display_pose_unstable = display_pose_unstable\n",
    "        self.display_pose_stable = display_pose_stable\n",
    "        self.display_pose_axis = display_pose_axis\n",
    "        \n",
    "        # Start the stream\n",
    "        self.start_stream()\n",
    "        \n",
    "        # Loop and stream\n",
    "        while True:\n",
    "            # Process each frame \n",
    "            self.process_frame()\n",
    "                    \n",
    "            # Show the frame\n",
    "            cv2.imshow(\"Frame\", self.frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "            \n",
    "            # If the `q` key was pressed, break from the loop.\n",
    "            if key == ord(\"q\"):\n",
    "                # Do some cleanup \n",
    "                self.end_stream()\n",
    "                break\n",
    "        \n",
    "    def start_stream(self):\n",
    "        self.set_params()\n",
    "        if self.filename:\n",
    "            self.vs = FileVideoStream(self.filename).start()\n",
    "        else:\n",
    "            self.vs = VideoStream(src=0).start()\n",
    "        print(\"[INFO] camera sensor warming up...\")\n",
    "        time.sleep(1.0)\n",
    "            \n",
    "    def end_stream(self):\n",
    "        # Do some cleanup\n",
    "        cv2.destroyAllWindows()\n",
    "        self.vs.stop()\n",
    "        del self.vs\n",
    "        self.num_frames = len(self.red)\n",
    "        self.frame_vector = range(self.num_frames)\n",
    "        \n",
    "    def set_params(self):\n",
    "        # Start default camera\n",
    "        video = cv2.VideoCapture(0)\n",
    "\n",
    "        # Find OpenCV version\n",
    "        (major_ver, minor_ver, subminor_ver) = (cv2.__version__).split('.')\n",
    "\n",
    "        if int(major_ver)  < 3 :\n",
    "            fps = video.get(cv2.cv.CV_CAP_PROP_FPS)\n",
    "            print(\"Frames per second using video.get(cv2.cv.CV_CAP_PROP_FPS): {0}\".format(fps))\n",
    "        else :\n",
    "            fps = video.get(cv2.CAP_PROP_FPS)\n",
    "            print(\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps))\n",
    "\n",
    "        # Number of frames to capture\n",
    "        num_frames = 30;\n",
    "\n",
    "        print(\"Capturing {0} frames\".format(num_frames))\n",
    "\n",
    "        # Start time\n",
    "        start = time.time()\n",
    "\n",
    "        # Grab a few frames\n",
    "        for i in range(0, num_frames):\n",
    "            ret, frame = video.read()\n",
    "\n",
    "        # End time\n",
    "        end = time.time()\n",
    "\n",
    "        # Time elapsed\n",
    "        seconds = end - start\n",
    "        print (\"Time taken : {0} seconds\".format(seconds))\n",
    "\n",
    "        # Calculate frames per second\n",
    "        # Round to 30 or 60\n",
    "        fps  = num_frames / seconds\n",
    "        possible_rates = [30, 60] # these are the possible rates that we can round to\n",
    "        self.fps = possible_rates[min(range(len(possible_rates)), key = lambda i: abs(possible_rates[i]-fps))] \n",
    "        print(\"Estimated frames per second : {0}\".format(self.fps))\n",
    "\n",
    "        # Find image dimensions and make the stablizer\n",
    "        frame = imutils.resize(video.read()[1], width=self.width)\n",
    "        self.height, _, _ = frame.shape\n",
    "        self.pose_estimator = PoseEstimator(img_size=(self.height, self.width))\n",
    "        self.pose_stabilizers = [Stabilizer(state_num=2, measure_num=1, cov_process=0.1, cov_measure=0.1) \n",
    "                            for _ in range(6)]\n",
    "        \n",
    "        # Set the frame limit \n",
    "        if self.fps == 30:\n",
    "            self.frame_limit = 64\n",
    "        else: # when fps = 60\n",
    "            self.frame_limit = 512\n",
    "        \n",
    "        # Release video\n",
    "        video.release()\n",
    "    \n",
    "    # Processes the signals when the frame limit has been reached\n",
    "    def process_signals(self):\n",
    "        self.apply_pos()\n",
    "        self.apply_rmns()\n",
    "        self.apply_freq_filtering()\n",
    "        self.append_window_signals()\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Processes the frame by updating numerical values and drawing on it (if specified)\n",
    "    def process_frame(self):\n",
    "        # Process and append the signals if the frame_limit is reached \n",
    "        if self.frame_count == self.frame_limit:\n",
    "            self.process_signals()\n",
    "        self.find_face()\n",
    "        self.loop_faces()\n",
    "        self.frame_count += 1\n",
    "    \n",
    "    # Finds faces in the image \n",
    "    def find_face(self):\n",
    "        # Read and resize the frame\n",
    "        self.frame = self.vs.read()\n",
    "        self.frame = imutils.resize(self.vs.read(), width=self.width)\n",
    "        # Get grayscale image and extract the bounding boxes with the detector \n",
    "        self.gray = cv2.cvtColor(self.frame, cv2.COLOR_BGR2GRAY)\n",
    "        self.rects = self.detector(self.gray, 0)\n",
    "    \n",
    "    # Loops over the faces to update values and to draw on the frame\n",
    "    def loop_faces(self):\n",
    "        for rect in self.rects:\n",
    "            # Get the bounding box \n",
    "            (self.bX, self.bY, self.bW, self.bH) = face_utils.rect_to_bb(rect)\n",
    "            # Determine the facial landmarks for the face region, then\n",
    "            # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "            # array.\n",
    "            self.shape = face_utils.shape_to_np(self.predictor(self.gray, rect))\n",
    "            # Set the facial points for the roi\n",
    "            self.set_face_points()\n",
    "            # Apply the aam\n",
    "            self.apply_aam()\n",
    "            # Get RGB values\n",
    "            self.update_rgb() \n",
    "            # Try pose estimation\n",
    "            self.pose = self.pose_estimator.solve_pose_by_68_points(\n",
    "                self.shape.astype('float'))\n",
    "            # Stabilize the pose\n",
    "            self.stablize_pose()\n",
    "            # Update RPY values \n",
    "            self.update_rpy()\n",
    "            # If a face is found, draw on the face\n",
    "            if self.shape.any():\n",
    "                self.draw_frame()\n",
    "                \n",
    "    def update_rgb(self):\n",
    "        self.red_window.append(np.sum(self.aam[:,:,0])/ self.num_aam_pixels)\n",
    "        self.green_window.append(np.sum(self.aam[:,:,1])/ self.num_aam_pixels)\n",
    "        self.blue_window.append(np.sum(self.aam[:,:,2])/ self.num_aam_pixels)\n",
    "\n",
    "    def update_rpy(self):\n",
    "        self.roll_window.append(self.steady_pose[0][2] * -1)\n",
    "        self.pitch_window.append(self.steady_pose[0][1])\n",
    "        self.yaw_window.append(self.steady_pose[0][0])\n",
    "    \n",
    "    # Applies the AAM by turning all cells outside of the face to 0\n",
    "    def apply_aam(self):\n",
    "        self.aam = np.zeros_like(self.frame)\n",
    "        \n",
    "        # Initialize masks \n",
    "        feature_mask = np.zeros((self.frame.shape[0], self.frame.shape[1]))  \n",
    "        l_eye_mask = np.zeros((self.frame.shape[0], self.frame.shape[1]))  \n",
    "        r_eye_mask = np.zeros((self.frame.shape[0], self.frame.shape[1]))  \n",
    "        custom_mask = np.zeros((self.frame.shape[0], self.frame.shape[1]))\n",
    "        \n",
    "        # Define hulls for the facial components \n",
    "        hull = cv2.convexHull(self.face_points)\n",
    "        hull_left_eye = cv2.convexHull(self.left_eye_points)\n",
    "        hull_right_eye = cv2.convexHull(self.right_eye_points)\n",
    "        custom_hull = cv2.convexHull(self.custom_points)\n",
    "        \n",
    "        # Fill the convex hulls for 1s, which mean that that pixel location is in the ROI.\n",
    "        feature_mask = cv2.fillConvexPoly(feature_mask, hull, 1).astype(np.bool)\n",
    "        l_eye_mask = cv2.fillConvexPoly(l_eye_mask, hull_left_eye, 1).astype(np.bool)\n",
    "        r_eye_mask = cv2.fillConvexPoly(r_eye_mask, hull_right_eye, 1).astype(np.bool)\n",
    "        custom_mask = cv2.fillConvexPoly(custom_mask, custom_hull, 1).astype(np.bool)\n",
    "        \n",
    "        # Use XOR to make a boolean mask of pixels inside our ROI\n",
    "        final_mask = np.logical_xor(feature_mask, l_eye_mask)\n",
    "        final_mask = np.logical_xor(final_mask, r_eye_mask)\n",
    "        \n",
    "        custom_final_mask = np.logical_xor(custom_mask, l_eye_mask)\n",
    "        self.custom_final_mask = np.logical_xor(custom_final_mask, r_eye_mask)\n",
    "        \n",
    "        # Final AAM\n",
    "        self.aam[self.custom_final_mask] = self.frame[self.custom_final_mask]\n",
    "        self.num_aam_pixels = np.sum(self.custom_final_mask)\n",
    "    \n",
    "    # Apply POS to combine rgb signal in to rPPG signal\n",
    "    def apply_pos(self):\n",
    "        self.red_window = self.normalize_signal(self.red_window)\n",
    "        self.green_window = self.normalize_signal(self.green_window)\n",
    "        self.blue_window = self.normalize_signal(self.blue_window)\n",
    "        C = np.array([self.red_window, self.green_window, self.blue_window])\n",
    "        mean_color = np.mean(C, axis=1)\n",
    "        diag_mean_color = np.diag(mean_color)\n",
    "        diag_mean_color_inv = np.linalg.inv(diag_mean_color)\n",
    "        Cn = np.matmul(diag_mean_color_inv,C)\n",
    "        projection_matrix = np.array([[0,1,-1],[-2,1,1]])\n",
    "        self.S_window = np.matmul(projection_matrix,Cn)\n",
    "        std = np.array([1,np.std(self.S_window[0,:])/np.std(self.S_window[1,:])])\n",
    "        self.P_window = np.matmul(std,self.S_window)\n",
    "        self.rppg_window = self.P_window-np.mean(self.P_window)\n",
    "        \n",
    "    # empircally play with the normalizing in the freq domain\n",
    "    # normalize RPY and RGB \n",
    "    # RPY - 45 and +45 -> []\n",
    "    # RPY to freq -> normalize -> combine (average)\n",
    "    # todo - fix scale of rpy_fft signal\n",
    "    # Applies Rhythmic Motion Noise Suppresion\n",
    "    def apply_rmns(self):\n",
    "        # Method 1: 1) temporal normalize RPY 2) FFT of normalized signals 3) combine\n",
    "        # Normalize RPY signals\n",
    "        self.roll_window = self.normalize_signal(self.roll_window)\n",
    "        self.pitch_window = self.normalize_signal(self.pitch_window)\n",
    "        self.yaw_window = self.normalize_signal(self.yaw_window)\n",
    "        # Find fft of RPY and rPPG signals\n",
    "        self.rppg_fft_window = np.abs(fft(self.rppg_window))\n",
    "        self.roll_fft_window = np.abs(fft(self.roll_window))\n",
    "        self.pitch_fft_window = np.abs(fft(self.pitch_window))\n",
    "        self.yaw_fft_window = np.abs(fft(self.yaw_window))\n",
    "        # Combine rpy_fft signals via averaging (divide by 3)\n",
    "        self.combined_rpy_fft_window = (self.roll_fft_window + self.pitch_fft_window + self.yaw_fft_window)/3\n",
    "        \n",
    "        # Method 2: 1) FFT 2) normalize FFT 3) combine\n",
    "        # take FFT\n",
    "#         self.rppg_fft_window = np.abs(fft(self.rppg_window))\n",
    "#         self.roll_fft_window = np.abs(fft(self.roll_window))\n",
    "#         self.pitch_fft_window = np.abs(fft(self.pitch_window))\n",
    "#         self.yaw_fft_window = np.abs(fft(self.yaw_window))\n",
    "#         # Normalize\n",
    "#         self.roll_fft_window = self.normalize_signal(self.roll_fft_window)\n",
    "#         self.pitch_fft_window = self.normalize_signal(self.pitch_fft_window)\n",
    "#         self.yaw_fft_window = self.normalize_signal(self.yaw_fft_window)\n",
    "#         # Combine rpy_fft signals via averaging (divide by 3)\n",
    "#         self.combined_rpy_fft_window = (self.roll_fft_window + self.pitch_fft_window + self.yaw_fft_window)/3\n",
    "        \n",
    "#         # Method 3: 1) FFT 2) combine 3)normalize\n",
    "#         # take FFT\n",
    "#         self.rppg_fft_window = np.abs(fft(self.rppg_window))\n",
    "#         self.roll_fft_window = np.abs(fft(self.roll_window))\n",
    "#         self.pitch_fft_window = np.abs(fft(self.pitch_window))\n",
    "#         self.yaw_fft_window = np.abs(fft(self.yaw_window))\n",
    "#         # Combine rpy_fft signals via averaging (divide by 3)\n",
    "#         self.combined_rpy_fft_window = self.normalize_signal((self.roll_fft_window + self.pitch_fft_window + self.yaw_fft_window)/3)\n",
    "        \n",
    "        # Apply RMNS\n",
    "        self.rppg_fft_rmns_window = self.rppg_fft_window - self.combined_rpy_fft_window\n",
    "        self.rppg_fft_rmns_window = self.rppg_fft_window\n",
    "        \n",
    "    def stablize_pose(self):\n",
    "        self.steady_pose = []\n",
    "        pose_np = np.array(self.pose).flatten()\n",
    "        for value, ps_stb in zip(pose_np, self.pose_stabilizers):\n",
    "            ps_stb.update([value])\n",
    "            self.steady_pose.append(ps_stb.state[0])\n",
    "        self.steady_pose = np.reshape(self.steady_pose, (-1, 3))\n",
    "    \n",
    "    def set_face_points(self):\n",
    "        # x,y locations of the facial landmarks\n",
    "        self.face_points = self.shape[self.facial_landmarks_idxs['face'][0]:self.facial_landmarks_idxs['face'][1]]\n",
    "        self.left_eye_points = self.shape[self.facial_landmarks_idxs['left_eye'][0]:self.facial_landmarks_idxs['left_eye'][1]]\n",
    "        self.right_eye_points = self.shape[self.facial_landmarks_idxs['right_eye'][0]:self.facial_landmarks_idxs['right_eye'][1]]\n",
    "\n",
    "        # Define custom ROI\n",
    "        custom_roi = [0,1,2,3,13,14,15,16,17,18,19,20,21,22,23,24,25,26,33]\n",
    "        avg_1 = np.asarray([np.mean([self.shape[3][0], self.shape[48][0]],dtype=np.int64), np.mean([self.shape[3][1],self.shape[48][1]],dtype=np.int64)])\n",
    "        avg_2 = np.asarray([np.mean([self.shape[13][0], self.shape[54][0]],dtype=np.int64), np.mean([self.shape[13][1],self.shape[54][1]])],dtype=np.int64)\n",
    "        points = [self.shape[i] for i in custom_roi]\n",
    "        points.extend([avg_1, avg_2])\n",
    "        self.custom_points = np.asarray(points)\n",
    "    \n",
    "    # TODO - Fix freq filtering\n",
    "    def apply_freq_filtering(self):\n",
    "        # use bandpass filter\n",
    "        self.rppg_freq_filtered_window = np.abs(ifft(self.rppg_fft_rmns_window))\n",
    "        \n",
    "    # normalize RGB signal by dividing by mean\n",
    "    def normalize_signal(self, signal):\n",
    "        signal = signal/np.mean(signal)\n",
    "        return signal\n",
    "    \n",
    "    def resample_signal(self, signal):\n",
    "        return signal\n",
    "        \n",
    "    def append_window_signals(self):\n",
    "        print('append called')\n",
    "        # RGB signals\n",
    "        self.red.extend(self.red_window)\n",
    "        self.green.extend(self.green_window)\n",
    "        self.blue.extend(self.blue_window)\n",
    "        \n",
    "        # RPY signals\n",
    "        self.roll.extend(self.roll_window)\n",
    "        self.pitch.extend(self.pitch_window)\n",
    "        self.yaw.extend(self.yaw_window)\n",
    "        \n",
    "        # POS Signals\n",
    "        self.S1.extend(self.S_window[0,:])\n",
    "        self.S2.extend(self.S_window[1,:])\n",
    "        self.P.extend(self.P_window)\n",
    "        \n",
    "        # rPPG\n",
    "        self.rppg.extend(self.rppg_window)\n",
    "        \n",
    "        # fft signals\n",
    "        self.roll_fft.extend(self.roll_fft_window)\n",
    "        self.pitch_fft.extend(self.pitch_fft_window)\n",
    "        self.yaw_fft.extend(self.yaw_fft_window)\n",
    "        \n",
    "        self.rppg_fft.extend(self.rppg_fft_window)\n",
    "        \n",
    "        # RMNS\n",
    "        self.combined_rpy_fft.extend(self.combined_rpy_fft_window)\n",
    "        self.rppg_fft_rmns.extend(self.rppg_fft_rmns_window)\n",
    "        \n",
    "        # Freq filtered signals\n",
    "        self.rppg_freq_filtered.extend(self.rppg_freq_filtered_window)\n",
    "        \n",
    "        self.reset_window_signals()\n",
    "        \n",
    "    def reset_window_signals(self):\n",
    "        # Frame count\n",
    "        self.frame_count = 0\n",
    "        # RGB signals\n",
    "        self.red_window = []\n",
    "        self.green_window = []\n",
    "        self.blue_window = []\n",
    "        \n",
    "        # RPY signals\n",
    "        self.roll_window = []\n",
    "        self.pitch_window = []\n",
    "        self.yaw_window = []\n",
    "        \n",
    "    def draw_frame(self):\n",
    "        if self.display_aam:\n",
    "            self.draw_overlay()\n",
    "        # Display bounding box if true\n",
    "        if self.display_face_bb:\n",
    "            self.draw_face_bb()\n",
    "        # Display facial landmarks if true\n",
    "        if self.display_landmarks:\n",
    "            self.draw_landmarks()\n",
    "        # Display the landmark overlay if true\n",
    "        if self.display_overlay:\n",
    "            self.draw_overlay()\n",
    "        # Display the pose if true\n",
    "        if self.display_pose_unstable or self.display_pose_stable:\n",
    "            self.draw_pose()\n",
    "        # Display the pose axis if true\n",
    "        if self.display_pose_axis:\n",
    "            self.draw_pose_axis()\n",
    "                        \n",
    "    def draw_face_bb(self):\n",
    "        # Draw the bounding box on the frame\n",
    "        cv2.rectangle(self.frame, (self.bX, self.bY), \n",
    "                      (self.bW+self.bX, self.bH+self.bY), (0, 255, 0), 1)\n",
    "    \n",
    "    def draw_landmarks(self):\n",
    "        for (name, (i, j)) in self.facial_landmarks_idxs.items():\n",
    "            # Loop over the subset of facial landmarks, drawing the specific face part\n",
    "            for (x, y) in self.shape[i:j]:\n",
    "                cv2.circle(self.frame, (x, y), 1, (0, 0, 255), -1)\n",
    "    \n",
    "    # Displays the overlay of the landmarks \n",
    "    def draw_overlay(self, alpha=0.75):\n",
    "        # Apply the transparent overlay\n",
    "#         cv2.addWeighted(self.aam, alpha, self.frame, 1 - alpha, 0,self.frame)\n",
    "        # apply a color\n",
    "        self.frame[self.custom_final_mask] = self.colors[0]\n",
    "\n",
    "    \n",
    "    def draw_pose(self):\n",
    "        # Display the initial pose annotation if true\n",
    "        if self.display_pose_unstable:\n",
    "            self.pose_estimator.draw_annotation_box(\n",
    "                self.frame, self.pose[0], self.pose[1], \n",
    "                color=(255, 128, 128))\n",
    "        # Display the stablized pose annotation if true\n",
    "        if self.display_pose_stable:\n",
    "            self.pose_estimator.draw_annotation_box(\n",
    "                self.frame, self.steady_pose[0], self.steady_pose[1], \n",
    "                color=(128, 255, 128))\n",
    "        \n",
    "    def draw_pose_axis(self):\n",
    "        self.pose_estimator.draw_axis(self.frame, \n",
    "                                      self.steady_pose[0], self.steady_pose[1])\n",
    "        \n",
    "    def plot_rgb(self):\n",
    "        plt.title('Normalized RGB values as a function of frames')\n",
    "        plt.plot(self.frame_vector, self.red, color='red', label = 'Red')\n",
    "        plt.plot(self.frame_vector, self.green, color='green', label='Green')\n",
    "        plt.plot(self.frame_vector, self.blue, color='blue', label='Blue')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        \n",
    "    def plot_projected_signal(self):\n",
    "        plt.title('Projected Signals')\n",
    "        plt.plot(self.frame_vector, self.S1)\n",
    "        plt.plot(self.frame_vector, self.S2)\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "        \n",
    "    def plot_rppg(self):\n",
    "        plt.title('rPPG signal')\n",
    "        plt.plot(self.frame_vector, self.rppg)\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "    \n",
    "    def plot_rpy(self):\n",
    "        plt.title('RPY values as a function of frames')\n",
    "        plt.plot(self.frame_vector, self.roll, color='cyan', label = 'Roll')\n",
    "        plt.plot(self.frame_vector, self.pitch, color='magenta', label='Pitch')\n",
    "        plt.plot(self.frame_vector, self.yaw, color='yellow', label='Yaw')\n",
    "        plt.xlabel('Frame')\n",
    "        plt.ylabel('Value')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        \n",
    "    def plot_fft(self):\n",
    "        plt.title('FFT of RPY and rPPG signals')\n",
    "        plt.plot(self.frame_vector, self.rppg_fft, label = 'rPPG')\n",
    "        plt.plot(self.frame_vector, self.roll_fft, color='cyan', label = 'Roll')\n",
    "        plt.plot(self.frame_vector, self.pitch_fft, color='magenta', label='Pitch')\n",
    "        plt.plot(self.frame_vector, self.yaw_fft, color='yellow', label='Yaw')\n",
    "        plt.legend(loc = 'upper right')\n",
    "        \n",
    "    def plot_combined_rpy_fft(self):\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.title('Combined FFT of RPY signal')\n",
    "        plt.plot(self.frame_vector, self.combined_rpy_fft)\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.title('Combined FFT of rPPG signal')\n",
    "        plt.plot(self.frame_vector, self.rppg_fft)\n",
    "        \n",
    "    def plot_rppg_rmns(self):\n",
    "        plt.title('FFT of rPPG signal after Rhythmic Noise Suppression')\n",
    "        plt.plot(self.frame_vector, self.rppg_fft_rmns)\n",
    "\n",
    "    def plot_rppg_freq_filtered(self):\n",
    "        plt.title('rPPG after Frequency Filter')\n",
    "        plt.plot(self.frame_vector, self.rppg_freq_filtered)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second using video.get(cv2.CAP_PROP_FPS) : 30.0\n",
      "Capturing 30 frames\n",
      "Time taken : 1.9945697784423828 seconds\n",
      "Estimated frames per second : 30\n",
      "successful init\n",
      "[INFO] camera sensor warming up...\n"
     ]
    }
   ],
   "source": [
    "predictor_path = \"../models/shape_predictor_68_face_landmarks.dat\"\n",
    "fs = face_streamer(predictor_path)\n",
    "# If display_aam is true, this is all you will see\n",
    "fs.stream(display_face_bb = False, display_landmarks = True, display_overlay = False, display_aam = True,\n",
    "          display_pose_unstable = False, display_pose_stable = True, display_pose_axis = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph RGB\n",
    "fs.plot_rgb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projected signal\n",
    "fs.plot_projected_signal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P \n",
    "plt.title('P signal')\n",
    "plt.plot(fs.frame_vector, fs.P)\n",
    "plt.xlabel('Frame')\n",
    "plt.ylabel('Value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph rPPG signals\n",
    "fs.plot_rppg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph RPY\n",
    "fs.plot_rpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph FFT of RGB and RPY signals signals\n",
    "fs.plot_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graph the combined RPY FFT\n",
    "fs.plot_combined_rpy_fft()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph the rPPG FFT after Rhythmic Noise Suppression\n",
    "fs.plot_rppg_rmns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Graph the rPPG after frequency filtering\n",
    "fs.plot_rppg_freq_filtered()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hand-cleaned PPG signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/media/brandon/Seagate HDD/datasets/vicarPPG/GroundTruth/PPG/Cleaned/01-base PPG.csv')\n",
    "stop = 1000\n",
    "plt.plot(df['Time'][:stop],df['Signal'][:stop])\n",
    "peaks = [df['Time'][idx] for idx, element in enumerate(df['Peaks']) if element == 1]\n",
    "\n",
    "for peak in peaks:\n",
    "    if peak >= df['Time'][stop]:\n",
    "        break\n",
    "    plt.axvline(x = peak, color = 'r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
